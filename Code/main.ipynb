{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Welcome to Medical image processing in Python***<br/>\n",
    "\n",
    "Presented by: Reza Saadatyar (2024-2025) <br/>\n",
    "E-mail: Reza.Saadatyar@outlook.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the require library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from Functions import Data_path\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from colorama import Back, Fore\n",
    "# from skimage.viewer import ImageViewer\n",
    "# from OOP import Pre_Processing_R2g\n",
    "# from Functions import image_resizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Set Image Path & Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"D:/Medical-Image-Processing/Data/Inputs/\"\n",
    "files_inputs, _, _ = Data_path.data_path(folder_path, data_format=\"tif\")\n",
    "\n",
    "folder_path = \"D:/Medical-Image-Processing/Data/Masks/\"\n",
    "files_masks, _, _ = Data_path.data_path(folder_path, data_format=\"TIF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Image-Width: n*<br/>\n",
    "*Image-Height: m*<br/>\n",
    "*Channels: c*<br/>\n",
    "*Planes: p*<br/>\n",
    "*Grayscale: (p, m, n)*<br/>\n",
    "*RGB: (p, m, n, c)*<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Convert the image into an array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Import numpy for array manipulation\n",
    "from skimage import io  # Import scikit-image library for image I/O operations\n",
    "\n",
    "class ImageDatasetLoader:\n",
    "    \"\"\"\n",
    "    A class to load and process images from file paths into a NumPy array.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_paths: str) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the ImageDatasetLoader class.\n",
    "        :param file_paths: List of file paths to images.\n",
    "        \"\"\"\n",
    "        self.images = None  # Placeholder for loaded image array\n",
    "        self.labels = None  # Placeholder for labels, if any\n",
    "        self.img_width = None  # Width of the images\n",
    "        self.img_height = None  # Height of the images\n",
    "        self.img_channels = None  # Number of color channels in the images\n",
    "        self.file_paths = file_paths  # Store the file input list\n",
    "\n",
    "    @property\n",
    "    def load_images(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Load images from the provided file paths into a NumPy array.\n",
    "        \"\"\"\n",
    "        if not self.file_paths:\n",
    "            raise ValueError(\"No file paths provided.\")  # Raise an error if no files are given\n",
    "\n",
    "        num_files = len(self.file_paths)  # Number of input files\n",
    "        data = io.imread(self.file_paths[0])  # Load the first image to get dimensions\n",
    "\n",
    "        if data.ndim == 2:  # Check if the image is grayscale\n",
    "            self.img_height, self.img_width = data.shape  # Get dimensions for grayscale image\n",
    "            self.images = np.zeros(  # Initialize array for grayscale images\n",
    "                (num_files, self.img_height, self.img_width),\n",
    "                dtype=np.uint8  # Use unsigned 8-bit integer for pixel values\n",
    "            )\n",
    "        else:  # Image is colored (e.g., RGB)\n",
    "            self.img_height, self.img_width, self.img_channels = data.shape  # Get dimensions for colored image\n",
    "            self.images = np.zeros(  # Initialize array for colored images\n",
    "                (num_files, self.img_height, self.img_width, self.img_channels),\n",
    "                dtype=np.uint8\n",
    "            )\n",
    "\n",
    "        for idx, file_path in enumerate(self.file_paths):  # Iterate through all file paths\n",
    "            self.images[idx] = io.imread(file_path)  # Read each image and store in the array\n",
    "\n",
    "        return self.images  # Return the loaded image array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1. Convert the images in the \"Inputs\" folder to a NumPy array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 768, 896, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = ImageDatasetLoader(files_inputs) # A class to load and process images from file paths into a NumPy array.\n",
    "inputs.load_images.shape  # Load images from the provided file paths into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 768, 896)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = ImageDatasetLoader(files_masks) # A class to load and process images from file paths into a NumPy array.\n",
    "masks.load_images.shape  # Load images from the provided file paths into a NumPy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2. Convert the images in the \"Masks\" folder to boolean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:00, 92.12it/s] \n"
     ]
    }
   ],
   "source": [
    "data = io.imread(files_inputs[0])  # Load a file for obtaining size data\n",
    "img_height = data.shape[0]         # Get the height of the image\n",
    "img_width = data.shape[1]          # Get the width of the image\n",
    "img_channels = data.shape[2]       # Get the number of channels in the image\n",
    "labels = np.zeros((len(files_inputs), img_height, img_width, 2), dtype = bool)  # Shape: [num_files, H, W, 2]\n",
    "\n",
    "sys.stdout.flush()\n",
    "for ind, _ in tqdm(enumerate(files_inputs)):  # Progressively iterate through all the input files\n",
    "    mask = np.squeeze(io.imread(files_masks[ind])).astype(bool)  # Load and convert each mask to boolean\n",
    "    labels[ind, :, :, 0] = ~mask  # Background (inverse of mask)\n",
    "    labels[ind, :, :, 1] = mask   # Foreground (actual mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Image Resizing](https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.resize)**<br/>\n",
    "`Standardizing Image Dimensions:` Machine learning models, like CNNs, need input data with fixed dimensions. For instance, if a model requires images of size 224x224x3, all input images must be resized to that shape.<br/>\n",
    "`Reducing Computational Load:`Resizing images to smaller dimensions lowers computational costs, particularly with large datasets, and aids in faster training or inference for deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmentation, Re_Color, & Im_Saving**<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "from skimage import transform, color  \n",
    "from tensorflow import keras\n",
    "\n",
    "#  ================================= Class for resizing & converting images ====================================\n",
    "class Image:\n",
    "    def __init__(self, img_data: np.ndarray):\n",
    "        \"\"\"\n",
    "        :param imgs: A numpy array of shape [num_images, height, width, channels].\n",
    "        \"\"\"\n",
    "        self.img_data = img_data\n",
    "        \n",
    "    # ---------------------------------------------- Resizes ---------------------------------------------------\n",
    "    def resize_images(self, img_height_resized: int, img_width_resized: int, img_channels: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Resizes a batch of images to the specified height, width, and channels.\n",
    "\n",
    "        \n",
    "        :return: A numpy array of resized images.\n",
    "        \"\"\"\n",
    "        # Initialize an empty array to store resized images\n",
    "        resized_imgs = np.zeros(\n",
    "            (self.img_data.shape[0], img_height_resized, img_width_resized, img_channels),\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "        \n",
    "        # Loop through each image in the batch\n",
    "        for i in range(self.img_data.shape[0]):\n",
    "            # Resize the image to the target dimensions and store it\n",
    "            resized_imgs[i] = transform.resize(\n",
    "                self.img_data[i],\n",
    "                (img_height_resized, img_width_resized, img_channels),\n",
    "                preserve_range=True  # Preserve the range of pixel values\n",
    "            )\n",
    "            \n",
    "        return resized_imgs  # Return the resized images\n",
    "    \n",
    "    # ------------------------------------------ RGB images to grayscale ---------------------------------------\n",
    "    def rgb2gray_scale(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Converts the RGB images to grayscale.\n",
    "\n",
    "        :return: A numpy array of grayscale images.\n",
    "        \"\"\"\n",
    "\n",
    "        img_num, img_height, img_width, _ = self.img_data.shape\n",
    "        img_gray = np.zeros((img_num, img_height, img_width), dtype=np.uint8)\n",
    "\n",
    "        for i in range(img_num):\n",
    "            # img_gray[i] = (color.rgb2gray(self.img_data[i]) * 255).astype(np.uint8)  # scale back to [0, 255]\n",
    "\n",
    "            img_gray[i] = color.rgb2gray(self.img_data[i])\n",
    "        \n",
    "        return img_gray\n",
    "\n",
    "\n",
    "# ================================== Class for augmentation (rotation) =========================================\n",
    "class Augmentation:\n",
    "    def __init__(self, num_augmented_imag: int, imag_files_path: str, imag_augmented_path: str):\n",
    "        \"\"\"\n",
    "        Applies image augmentation (rotation) to images in the specified directory and saves them.\n",
    "\n",
    "        :param num_augmented_images: Number of augmented images to generate.\n",
    "        :param imag_files_path: Path to the directory containing the images.\n",
    "        :param imag_augmented_path: Path to the directory to save augmented images.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.imag_files_path = imag_files_path\n",
    "        self.num_augmented_imag = num_augmented_imag\n",
    "        self.imag_augmented_path = imag_augmented_path\n",
    "        \n",
    "    def augmented_images(self) -> None:\n",
    "        \n",
    "        dat = io.imread(glob.glob(self.imag_files_path + '/*')[0])\n",
    "        self.imag_augmented_path = os.path.join(self.imag_augmented_path, 'Rotated/')\n",
    "        os.makedirs(self.imag_augmented_path, exist_ok=True)  # Ensure the temporary folder is created\n",
    "        # Create a temporary folder inside the original folder for processing\n",
    "        TEMP_DIR = os.path.join(self.imag_files_path, 'Temp/')\n",
    "        os.makedirs(TEMP_DIR, exist_ok=True)  # Ensure the temporary folder is created\n",
    "        \n",
    "        # Copy all files from the main folder to the temporary folder\n",
    "        for filename in os.listdir(self.imag_files_path):\n",
    "            if filename.casefold().endswith(('.tif', '.jpg', '.png')):  # Correct usage with a tuple\n",
    "                shutil.copy(os.path.join(self.imag_files_path, filename), os.path.join(TEMP_DIR, filename))\n",
    "   \n",
    "        # Set up the ImageDataGenerator for image augmentation\n",
    "        Data_Gen = keras.preprocessing.image.ImageDataGenerator(rotation_range=30)  # Rotate images randomly up to 30 degrees\n",
    "        # Use flow_from_directory to process the images in the Temp folder\n",
    "        img_aug = Data_Gen.flow_from_directory(\n",
    "            self.imag_files_path,     # Parent directory of Temp\n",
    "            classes=['Temp'],    # Specify the subfolder 'Temp' as the target\n",
    "            batch_size=1,        # Process one image at a time\n",
    "            save_to_dir=self.imag_augmented_path,  # Save augmented images to the Rotated folder\n",
    "            save_prefix='Aug',   # Prefix for augmented images\n",
    "            target_size=(dat.shape[0], dat.shape[1]),  # Resize images to the specified dimensions\n",
    "            class_mode=None      # No labels, as we're working with unclassified images\n",
    "        )\n",
    "        \n",
    "        for _ in range(self.num_augmented_imag):  # Generate augmented images and save them\n",
    "            next(img_aug)  # Process the next image and save it\n",
    "\n",
    "        shutil.rmtree(TEMP_DIR)  # Delete the temporary folder and its contents after processing\n",
    "\n",
    "    # ---------------------------------------------- Plot ------------------------------------------------------\n",
    "    def plot_img_original_augment(self, num_img: int) -> None:\n",
    "        \n",
    "        _, axs = plt.subplots(nrows=2, ncols=num_img)\n",
    "        \n",
    "        # Check if num_img is 1 (special case for 1 image)\n",
    "        if num_img == 1:\n",
    "            # Display images on the first row\n",
    "            # io.imread(files_inputs[0])[:, :, :3].shape\n",
    "            axs[0].imshow(io.imread(glob.glob(self.imag_files_path + '/*')[0]), cmap='gray')\n",
    "            axs[0].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)  # Hide ticks\n",
    "            [spine.set_visible(False) for spine in axs[0].spines.values()]  # Hide all spines\n",
    "            axs[0].set_ylabel(\"Original Images\", fontsize=12, labelpad=10)  # Y-axis label for the first row\n",
    "            \n",
    "            # Display images on the second row\n",
    "            axs[1].imshow(io.imread(glob.glob(self.imag_augmented_path + '/*')[0]), cmap='gray')\n",
    "            axs[1].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)  # Hide ticks\n",
    "            [spine.set_visible(False) for spine in axs[1].spines.values()]  # Hide all spines\n",
    "            axs[1].set_ylabel(\"Augmented Images\", fontsize=12, labelpad=10)  # Y-axis label for the second row\n",
    "\n",
    "        else:\n",
    "            for i in range(num_img):\n",
    "                # Display images on the first row\n",
    "                axs[0, i].imshow(io.imread(glob.glob(self.imag_files_path + '/*')[i]), cmap='gray')\n",
    "                axs[0, i].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)  # Hide ticks\n",
    "                [spine.set_visible(False) for spine in axs[0, i].spines.values()]  # Hide all spines\n",
    "\n",
    "                # Display images on the second row\n",
    "                axs[1, i].imshow(io.imread(glob.glob(self.imag_augmented_path + '/*')[i]), cmap='gray')\n",
    "                axs[1, i].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)  # Hide ticks\n",
    "                [spine.set_visible(False) for spine in axs[1, i].spines.values()]  # Hide all spines\n",
    "\n",
    "            # Add ylabel for each row (only set ylabel for the first column of each row)\n",
    "            axs[0, 0].set_ylabel(\"Original Images\", fontsize=12, labelpad=10)  # Y-axis label for the first row\n",
    "            axs[1, 0].set_ylabel(\"Augmented Images\", fontsize=12, labelpad=10)  # Y-axis label for the second row\n",
    "\n",
    "        # Adjust layout to make sure images and titles don't overlap\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Auto-scale to fit the images in the figure area\n",
    "        plt.autoscale(enable=True, axis='both', tight=True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ==================================== Class for RGB images to grayscale # =====================================\n",
    "class RGB2Gray:\n",
    "    def __init__(self, files_path: str) -> None:\n",
    "        self.files_path = files_path\n",
    "    \n",
    "    def rgb2gray_scale(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Converts the RGB images to grayscale.\n",
    "\n",
    "        :return: A numpy array of grayscale images.\n",
    "        \"\"\"\n",
    "        io.imread(glob.glob(self.files_path + '/*'))\n",
    "        img_num, img_height, img_width, _ = self.img_data.shape\n",
    "        img_gray = np.zeros((img_num, img_height, img_width), dtype=np.uint8)\n",
    "\n",
    "        for i in range(img_num):\n",
    "            # img_gray[i] = (color.rgb2gray(self.img_data[i]) * 255).astype(np.uint8)  # scale back to [0, 255]\n",
    "\n",
    "            img_gray[i] = color.rgb2gray(self.img_data[i])\n",
    "        \n",
    "        return img_gray\n",
    "\n",
    "\n",
    "img = Image(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:/Medical-Image-Processing/Data/Inputs\\\\ytma12_010804_benign2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma12_010804_benign3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma12_010804_malignant1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma12_010804_malignant2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma12_010804_malignant3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma23_022103_benign1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma23_022103_benign2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma23_022103_benign3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma23_022103_malignant1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma23_022103_malignant2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma23_022103_malignant3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042003_benign1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042003_benign2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042003_benign3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042003_malignant1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042003_malignant2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042003_malignant3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042203_benign1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042203_benign2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042203_benign3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042203_malignant1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042203_malignant2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042203_malignant3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042403_benign1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042403_benign2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042403_benign3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042403_malignant1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042403_malignant2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_042403_malignant3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_072303_benign1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_072303_benign2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_072303_malignant1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_072303_malignant2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_111003_benign1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_111003_benign2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_111003_benign3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_111003_malignant1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_111003_malignant2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_111003_malignant3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_111303_benign1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_111303_benign2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_111303_benign3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_111303_malignant1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_111303_malignant2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma49_111303_malignant3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma55_030603_benign1_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma55_030603_benign2_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma55_030603_benign3_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma55_030603_benign4_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma55_030603_benign5_ccd.tif', 'D:/Medical-Image-Processing/Data/Inputs\\\\ytma55_030603_benign6_ccd.tif']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder path\n",
    "files_path = \"D:/Medical-Image-Processing/Data/Inputs\"\n",
    "\n",
    "# Get the full path and filenames of files in the folder (excluding subfolders)\n",
    "files_with_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) \n",
    "                    if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "print(files_with_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================== Class for RGB images to grayscale # =====================================\n",
    "class RGB2Gray:\n",
    "    def __init__(self, files_path: str, save_fig: str=\"off\") -> None:\n",
    "        self.save_fig = save_fig\n",
    "        self.files_path = files_path\n",
    "\n",
    "    @property\n",
    "    def rgb_convert_gray(self) -> np.ndarray:\n",
    "        \n",
    "       # Get the full path and filenames of files in the folder (excluding subfolders)\n",
    "        files_with_paths = [os.path.join(self.files_path, f) for f in os.listdir(self.files_path) \n",
    "                    if os.path.isfile(os.path.join(self.files_path, f))]\n",
    "\n",
    "        img_num = len(files_with_paths)\n",
    "        img_height, img_width, _ = io.imread(files_with_paths[0]).shape\n",
    "        img_gray = np.zeros((img_num, img_height, img_width), dtype=np.uint8)\n",
    "\n",
    "        for i in range(img_num):\n",
    "            img_gray[i] = (color.rgb2gray(io.imread(files_with_paths[i])) * 255).astype(np.uint8)  # scale back to [0, 255]\n",
    "        \n",
    "        if self.save_fig == \"on\":\n",
    "            \n",
    "            \n",
    "        return img_gray\n",
    "    \n",
    "    # def save_img_gray(self, path_save):\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 --> ytma12_010804_benign2_ccd.tif\n",
      "2 --> ytma12_010804_benign3_ccd.tif\n",
      "3 --> ytma12_010804_malignant1_ccd.tif\n",
      "4 --> ytma12_010804_malignant2_ccd.tif\n",
      "5 --> ytma12_010804_malignant3_ccd.tif\n",
      "6 --> ytma23_022103_benign1_ccd.tif\n",
      "7 --> ytma23_022103_benign2_ccd.tif\n",
      "8 --> ytma23_022103_benign3_ccd.tif\n",
      "9 --> ytma23_022103_malignant1_ccd.tif\n",
      "10 --> ytma23_022103_malignant2_ccd.tif\n",
      "11 --> ytma23_022103_malignant3_ccd.tif\n",
      "12 --> ytma49_042003_benign1_ccd.tif\n",
      "13 --> ytma49_042003_benign2_ccd.tif\n",
      "14 --> ytma49_042003_benign3_ccd.tif\n",
      "15 --> ytma49_042003_malignant1_ccd.tif\n",
      "16 --> ytma49_042003_malignant2_ccd.tif\n",
      "17 --> ytma49_042003_malignant3_ccd.tif\n",
      "18 --> ytma49_042203_benign1_ccd.tif\n",
      "19 --> ytma49_042203_benign2_ccd.tif\n",
      "20 --> ytma49_042203_benign3_ccd.tif\n",
      "21 --> ytma49_042203_malignant1_ccd.tif\n",
      "22 --> ytma49_042203_malignant2_ccd.tif\n",
      "23 --> ytma49_042203_malignant3_ccd.tif\n",
      "24 --> ytma49_042403_benign1_ccd.tif\n",
      "25 --> ytma49_042403_benign2_ccd.tif\n",
      "26 --> ytma49_042403_benign3_ccd.tif\n",
      "27 --> ytma49_042403_malignant1_ccd.tif\n",
      "28 --> ytma49_042403_malignant2_ccd.tif\n",
      "29 --> ytma49_042403_malignant3_ccd.tif\n",
      "30 --> ytma49_072303_benign1_ccd.tif\n",
      "31 --> ytma49_072303_benign2_ccd.tif\n",
      "32 --> ytma49_072303_malignant1_ccd.tif\n",
      "33 --> ytma49_072303_malignant2_ccd.tif\n",
      "34 --> ytma49_111003_benign1_ccd.tif\n",
      "35 --> ytma49_111003_benign2_ccd.tif\n",
      "36 --> ytma49_111003_benign3_ccd.tif\n",
      "37 --> ytma49_111003_malignant1_ccd.tif\n",
      "38 --> ytma49_111003_malignant2_ccd.tif\n",
      "39 --> ytma49_111003_malignant3_ccd.tif\n",
      "40 --> ytma49_111303_benign1_ccd.tif\n",
      "41 --> ytma49_111303_benign2_ccd.tif\n",
      "42 --> ytma49_111303_benign3_ccd.tif\n",
      "43 --> ytma49_111303_malignant1_ccd.tif\n",
      "44 --> ytma49_111303_malignant2_ccd.tif\n",
      "45 --> ytma49_111303_malignant3_ccd.tif\n",
      "46 --> ytma55_030603_benign1_ccd.tif\n",
      "47 --> ytma55_030603_benign2_ccd.tif\n",
      "48 --> ytma55_030603_benign3_ccd.tif\n",
      "49 --> ytma55_030603_benign4_ccd.tif\n",
      "50 --> ytma55_030603_benign5_ccd.tif\n",
      "51 --> ytma55_030603_benign6_ccd.tif\n"
     ]
    }
   ],
   "source": [
    "path_save = 'D:/Medical-Image-Processing/Data/'\n",
    "img_gray = a \n",
    "os.makedirs(os.path.join(path_save, 'Gray image/'), exist_ok=True)  # Ensure the temporary folder is created\n",
    "for ind, filename in enumerate(os.listdir(files_path)):\n",
    "     if os.path.isfile(os.path.join(files_path, filename)):\n",
    "        print(ind, '-->', filename)\n",
    "      #   io.imsave(fname='{}{}'.format(path_save + 'Gray image/', filename), arr=img_gray[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "New = 'D:/Python/Breast/'\n",
    "\n",
    "def Pre_Process_Im_Saving(Path_Images, Path_Output, Tensor):\n",
    "    \n",
    "    for i, filename in enumerate(os.listdir(Path_Images)):\n",
    "        \n",
    "        imsave(fname='{}{}'.format(Path_Output, filename),\n",
    "               arr=Tensor[i])\n",
    "        \n",
    "        print('{}: {}'.format(i, filename))\n",
    "    \n",
    "Pre_Process_Im_Saving(IMAGE_PATH, New, Gray_Scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 768, 896)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_ = RGB2Gray(files_path)\n",
    "a = rgb_.rgb_convert_gray\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2][10:15][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fore.RED + Resizing images from (58, 768, 896, 3) to (58, 255, 255, 3)\n"
     ]
    }
   ],
   "source": [
    "# Resizing the images\n",
    "resized_images = img.resize_images(img_height_resized=255, img_width_resized=255, img_channels=3)\n",
    "print(f\" Fore.RED + Resizing images from {inputs.shape} to {resized_images.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 768, 896)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = img.rgb2gray_scale()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "num_augmented_imag = 3\n",
    "# Path to the folder containing the original images\n",
    "imag_files_path = 'D:/Medical-Image-Processing/Data/Inputs/A/B/C/'\n",
    "\n",
    "# Path where augmented images will be saved\n",
    "imag_augmented_path = 'D:/Medical-Image-Processing/Data/'\n",
    "augm = Augmentation(num_augmented_imag, imag_files_path, imag_augmented_path)\n",
    "augm.augmented_images()\n",
    "# resizer.augmented_images(num_augmented_imag, imag_files_path, imag_augmented_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augm.plot_img_original_augment(num_img=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = io.imread(glob.glob(imag_files_path + '/*')[0])\n",
    "dat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
